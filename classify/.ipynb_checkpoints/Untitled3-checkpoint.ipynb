{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b167029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from dataLoadProc import microPlankton\n",
    "\n",
    "#def netClassify(softCalFlag, paddingFlag, groupNum, netPath,imgPath,outputPath,labelLib,fileType, inputSize,batchSize,classes,saveClsaaFlag,respectivelyCountFlag,printScoreFlag, topFlag):\n",
    "netPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\modelGen\\shufflenet_v2_x1_5_10classes_batch326.pt'\n",
    "imgPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\samples\\test\\crop_withBackground/'\n",
    "outputPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\samples\\test\\result_withBackground10/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "labelLib=['Diatom_1', 'Diatom_2','Diatom_3','Diatom_4','Diatom_5','Copepod','Copepod_Nauplii','Ciliate','Ceratium_sp1','Ceratium_sp2']\n",
    "fileType = '.tif'\n",
    "inputSize = 400\n",
    "batchSize = 20\n",
    "drawImgFlag = True\n",
    "classes = 10\n",
    "paddingFlag = True\n",
    "saveClsaaFlag = True\n",
    "topFlag = True\n",
    "softCalFlag = True\n",
    "printScoreFlag = True\n",
    "respectivelyCountFlag = True\n",
    "modelUse = torch.load(netPath)\n",
    "modelUse = modelUse.to(device)\n",
    "if paddingFlag:\n",
    "    imgTransform = transforms.Compose([#transforms.Pad(4, fill=0, padding_mode='constant'),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       # transforms.Normalize(),\n",
    "                                       ])\n",
    "else:\n",
    "    imgTransform = transforms.ToTensor()\n",
    "\n",
    "    # ----------------------get the img list START\n",
    "def getImg(directory):\n",
    "    txtfile  = []\n",
    "    for f in sorted(list(os.listdir(directory))):\n",
    "        if f.endswith(fileType):\n",
    "            if os.path.isfile(os.path.join(directory, f)):\n",
    "                a = os.path.join(directory, f)\n",
    "                txtfile.append(a)\n",
    "    return txtfile\n",
    "# ----------------------get the img list END\n",
    "\n",
    "file = getImg(imgPath)         #get the img list\n",
    "print(file)\n",
    "imgDataset = microPlankton(paddingFlag,inputSize, imgPath, file, imgTransform)\n",
    "print(len(imgDataset))\n",
    "imgDataloader = torch.utils.data.DataLoader(imgDataset,batch_size=batchSize,\n",
    "                                            shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "def predictClass(model, imgDataloader,softMaxCal, drawImgFlag, savePath):\n",
    "    topRecord = []\n",
    "    printOutList = []\n",
    "    topList = []\n",
    "    for input in imgDataloader:\n",
    "        input = input.to(device)\n",
    "        model.eval()\n",
    "        with torch.autograd.set_grad_enabled(False):\n",
    "            out = model(input)\n",
    "            if softMaxCal:\n",
    "                softMax = nn.Softmax(dim=1)\n",
    "                out = softMax(out)\n",
    "            if printScoreFlag:\n",
    "                printOut = out.cpu().numpy()\n",
    "            # ps = torch.exp(out)\n",
    "            top = out.topk(1, dim=1)\n",
    "            if topFlag:\n",
    "                topScore = top[0].cpu().numpy()\n",
    "            top = top[1].cpu().numpy()\n",
    "            topRecord.append(str(top))\n",
    "            topList.append(topScore)\n",
    "            printOutList.append(printOut)\n",
    "    return topRecord,printOutList,topList\n",
    "\n",
    "def printFile(outputPath, classFile,classTotalNum, respectivelyCountFlag,scoreList,scoreFlag,topsList,topsFlag):\n",
    "\n",
    "\n",
    "    txtName = open(outputPath +'/'+ \"%05d\" % groupNum+'.txt', 'w')  # creat txt\n",
    "\n",
    "    for n in np.arange(0,classTotalNum):\n",
    "\n",
    "        classNum = str(classFile).replace(' ','').count('['+str(n)+']')\n",
    "        dataWrite = 'Number of '+ labelLib[n]+ ' is '+ str(classNum) + '\\n'  # write\n",
    "        txtName.write(dataWrite)\n",
    "    txtName.close()\n",
    "    if topsFlag:\n",
    "        topFile = open(outputPath + '/' + \"%05d\" % groupNum + '_topScore.txt', 'w')\n",
    "        topsList = str(topsList).replace(' ', '').replace(',dtype=float32)','').replace(\"\\n\",'').replace('array(','').replace('[','').replace('],', ' ').replace('],', ' ').replace(']', '').split(' ')\n",
    "\n",
    "        if scoreFlag:\n",
    "            scoreFile = open(outputPath + '/' + \"%05d\" % groupNum + '_score.txt', 'w')\n",
    "            scoreList  = str(scoreList).replace(' ', '').replace(',dtype=float32)','').replace(\"\\n\",'').replace('array(','').replace('[','').replace('],', ' ').replace('],', ' ').replace(']', '').split(' ')\n",
    "\n",
    "        if respectivelyCountFlag:\n",
    "            txtNameRes = open(outputPath + '/' + \"%05d\" % groupNum + '_Respectively.txt', 'w')  # creat txt\n",
    "            classFile = str(classFile).replace(' ','').replace('[','').replace(\"'\",'').replace(r']\\n',' ').replace(']', '').replace(',', ' ').split(' ')\n",
    "\n",
    "\n",
    "        for sortNum in np.arange(len(topsList)):\n",
    "            # tops = topsList[sortNum]\n",
    "            tops = \"%04d\" % sortNum + ': ' + str(topsList[sortNum])+ '\\n'\n",
    "            topFile.write(tops)\n",
    "            if scoreFlag:\n",
    "                # score = scoreList[sortNum]\n",
    "                score = \"%04d\" % sortNum + ': ' + str(scoreList[sortNum]) + '\\n'\n",
    "                scoreFile.write(score)\n",
    "            if respectivelyCountFlag:\n",
    "\n",
    "                a = classFile[sortNum]\n",
    "                if a is not '':  \n",
    "                #txtNameRes.write(\"%04d\" % sortNum + ': ' + labelLib[np.int(a)] + '\\n')\n",
    "                   txtNameRes.write(\"%04d\" % sortNum + ': ' + labelLib[np.int(a)] + '\\n')\n",
    "\n",
    "        topFile.close()\n",
    "        if scoreFlag:\n",
    "            scoreFile.close()\n",
    "        if respectivelyCountFlag:\n",
    "            txtNameRes.close()\n",
    "folderNum = len([lists for lists in os.listdir(imgPath) if os.path.isdir(os.path.join(imgPath, lists))])\n",
    "#for groupNum in np.arange(folderNum):\n",
    "    #imgPath_1 = imgPath + '/'+\"%05d\" % groupNum\n",
    "pre, scoreList, topList = predictClass(modelUse, imgDataloader,softCalFlag, drawImgFlag, imgPath)\n",
    "\n",
    "# print( time.time() - beginT)\n",
    "\n",
    "\n",
    "\n",
    "if saveClsaaFlag:\n",
    "    printFile(outputPath, pre, classes,respectivelyCountFlag,scoreList,printScoreFlag,topList, topFlag)\n",
    "else:\n",
    "    print(pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1b2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms,datasets\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from dataLoadProc import microPlankton\n",
    "\n",
    "#def netClassify(softCalFlag, paddingFlag, groupNum, netPath,imgPath,outputPath,labelLib,fileType, inputSize,batchSize,classes,saveClsaaFlag,respectivelyCountFlag,printScoreFlag, topFlag):\n",
    "netPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\modelGen\\shufflenet_v2_x1_5_10classes_batch326.pt'\n",
    "imgPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\samples\\test\\crop_withBackground/'\n",
    "outputPath = r'C:\\Users\\NayakLab\\Desktop\\Ranjoy_data\\EastSound_2015\\automated_classification\\holographic_plankton_classification-main\\samples\\test\\result_withBackground10/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device( \"cpu\")\n",
    "labelLib=['Diatom_1', 'Diatom_2','Diatom_3','Diatom_4','Diatom_5','Copepod','Copepod_Nauplii','Ciliate','Ceratium_sp1','Ceratium_sp2']\n",
    "fileType = '.tif'\n",
    "inputSize = 400\n",
    "batchSize = 20\n",
    "drawImgFlag = True\n",
    "classes = 10\n",
    "paddingFlag = True\n",
    "saveClsaaFlag = True\n",
    "topFlag = True\n",
    "softCalFlag = True\n",
    "respectivelyCountFlag = True\n",
    "modelUse = torch.load(netPath)\n",
    "modelUse = modelUse.to(device)\n",
    "if paddingFlag:\n",
    "    imgTransform = transforms.Compose([#transforms.Pad(4, fill=0, padding_mode='constant'),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       # transforms.Normalize(),\n",
    "                                       ])\n",
    "else:\n",
    "    imgTransform = transforms.ToTensor()\n",
    "\n",
    "    # ----------------------get the img list START\n",
    "def getImg(directory):\n",
    "    txtfile  = []\n",
    "    for f in sorted(list(os.listdir(directory))):\n",
    "        if f.endswith(fileType):\n",
    "            if os.path.isfile(os.path.join(directory, f)):\n",
    "                a = os.path.join(directory, f)\n",
    "                txtfile.append(a)\n",
    "    return txtfile\n",
    "# ----------------------get the img list END\n",
    "\n",
    "file = getImg(imgPath)         #get the img list\n",
    "imgDataset = microPlankton(paddingFlag,inputSize, imgPath, file, imgTransform)\n",
    "imgDataloader = torch.utils.data.DataLoader(imgDataset,batch_size=batchSize,\n",
    "                                            shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(imgDataloader)\n",
    "dae=[3,4,5,6]\n",
    "\n",
    "topRecord = []\n",
    "printOutList = []\n",
    "topList = []\n",
    "for input in imgDataloader:\n",
    "    input = input.to(device)\n",
    "    modelUse.eval()\n",
    "    with torch.autograd.set_grad_enabled(False):\n",
    "        out = modelUse(input)\n",
    "        if softMaxCal:\n",
    "            softMax = nn.Softmax(dim=1)\n",
    "            out = softMax(out)\n",
    "        if printScoreFlag:\n",
    "            printOut = out.cpu().numpy()\n",
    "        # ps = torch.exp(out)\n",
    "        top = out.topk(1, dim=1)\n",
    "        if topFlag:\n",
    "            topScore = top[0].cpu().numpy()\n",
    "        top = top[1].cpu().numpy()\n",
    "        topRecord.append(str(top))\n",
    "        topList.append(topScore)\n",
    "        printOutList.append(printOut)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ee777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "topRecord = []\n",
    "printOutList = []\n",
    "topList = []\n",
    "for input in imgDataloader:\n",
    "    input = input.to(device)\n",
    "    model.eval()\n",
    "    with torch.autograd.set_grad_enabled(False):\n",
    "        out = model(input)\n",
    "        if softMaxCal:\n",
    "            softMax = nn.Softmax(dim=1)\n",
    "            out = softMax(out)\n",
    "        if printScoreFlag:\n",
    "            printOut = out.cpu().numpy()\n",
    "        # ps = torch.exp(out)\n",
    "        top = out.topk(1, dim=1)\n",
    "        if topFlag:\n",
    "            topScore = top[0].cpu().numpy()\n",
    "        top = top[1].cpu().numpy()\n",
    "        topRecord.append(str(top))\n",
    "        topList.append(topScore)\n",
    "        printOutList.append(printOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a984d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device( \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e67602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
